import os
from dotenv import load_dotenv
import streamlit as st
from openai import OpenAI
from sentence_transformers import SentenceTransformer
from qdrant_client import QdrantClient

# --- ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ç”¨ï¼‰ ---
load_dotenv()

# --- APIã‚­ãƒ¼ãªã©ã®è¨­å®š ---
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
QDRANT_HOST = os.getenv("QDRANT_HOST")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")
COLLECTION_NAME = "line_rangers"

# --- OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ– ---
client_ai = OpenAI(api_key=OPENAI_API_KEY)

# --- Qdrant ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ– ---
qdrant = QdrantClient(
    url=QDRANT_HOST,
    api_key=QDRANT_API_KEY
)

# --- åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ ---
embedder = SentenceTransformer("all-MiniLM-L6-v2")

# --- é¡ä¼¼æ–‡æ›¸æ¤œç´¢ ---
def create_context(question: str, max_len: int = 2100) -> str:
    q_vector = embedder.encode([question])[0]
    search_result = qdrant.search(
        collection_name=COLLECTION_NAME,
        query_vector=q_vector,
        limit=4   # â† ã“ã“ã§å–å¾—ä»¶æ•°ã‚’èª¿æ•´ï¼ˆ3,5,7ãªã©å®Ÿé¨“å¯èƒ½ï¼‰
    )

    texts = []
    total_words = 0
    for point in search_result:
        text = point.payload.get("text", "")
        word_count = len(text.split())
        if total_words + word_count > max_len:
            break
        texts.append(text)
        total_words += word_count

    return "\n\n###\n\n".join(texts)

# --- GPT ã«å›ç­”ã‚’ä¾é ¼ ---
def answer_question(question: str, history: list) -> str:
    context = create_context(question)

    # ğŸ” ä»Šå›ã®å‚ç…§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜ã—ã¦ãŠãï¼ˆè¡¨ç¤ºç”¨ï¼‰
    st.session_state["last_context"] = context  

    prompt = f"""
ã‚ãªãŸã¯ã‚²ãƒ¼ãƒ ã®æ”»ç•¥æƒ…å ±ç™ºä¿¡è€…ã§ã™ã€‚
ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦ã€è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«æƒ…å ±ãŒãªã„å ´åˆã¯ã€Œã‚ã‹ã‚Šã¾ã›ã‚“ã€‚Youtubeã‚„Xãªã©ã®SNSãªã©ã«æƒ…å ±ãŒã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§ã€èª¿ã¹ã¦ã¿ã‚‹ã“ã¨ã‚’ãŠã™ã™ã‚ã—ã¾ã™ã€ã¨ç­”ãˆã¦ãã ã•ã„ã€‚

ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:
{context}

---
è³ªå•: {question}
å›ç­”:""".strip()

    history.append({"role": "user", "content": prompt})
    try:
        resp = client_ai.chat.completions.create(
            model="gpt-4.1-mini",
            messages=history,
            temperature=0.7
        )
        answer = resp.choiceas[0].message.content.strip()
        history.append({"role": "assistant", "content": answer})
        return answer
    except Exception as e:
        return f"âŒ ã‚¨ãƒ©ãƒ¼: {e}"

# --- Streamlit UI ---
st.set_page_config(page_title="LINEãƒ¬ãƒ³ã‚¸ãƒ£ãƒ¼Q&A", page_icon="ğŸ®")
st.title("ğŸ® LINEãƒ¬ãƒ³ã‚¸ãƒ£ãƒ¼Q&Aãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")

if "history" not in st.session_state:
    st.session_state.history = []

question = st.text_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š")

if st.button("é€ä¿¡") and question:
    with st.spinner("è€ƒãˆä¸­..."):
        answer = answer_question(question, st.session_state.history)
        st.markdown("---")
        st.markdown(f"**ã‚ãªãŸã®è³ªå•ï¼š** {question}")
        st.markdown(f"**AIã®å›ç­”ï¼š** {answer}")

        # ğŸ” ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç¢ºèªã‚’è¿½åŠ 
        if "last_context" in st.session_state:
            st.markdown("### ğŸ” ä»Šå›å‚ç…§ã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ")
            st.text(st.session_state["last_context"])
